/**
 * Meta-Cognition Module - R√©flexion sur la Qualit√© des R√©ponses
 * 
 * Ce module permet √† Phoenix de r√©fl√©chir sur ses propres r√©ponses
 * et de les am√©liorer avant de les livrer, comme Manus AI.
 * 
 * Fonctionnalit√©s:
 * 1. √âvaluation de la qualit√© des r√©ponses
 * 2. D√©tection des erreurs potentielles
 * 3. Auto-am√©lioration des r√©ponses
 * 4. Validation avant livraison
 */

import { invokeLLM } from '../_core/llm';

// Types pour la m√©ta-cognition
export interface QualityAssessment {
  id: string;
  responseId: string;
  scores: {
    relevance: number;      // Pertinence par rapport √† la demande
    completeness: number;   // Compl√©tude de la r√©ponse
    accuracy: number;       // Exactitude des informations
    clarity: number;        // Clart√© de l'expression
    helpfulness: number;    // Utilit√© pour l'utilisateur
  };
  overallScore: number;
  issues: QualityIssue[];
  suggestions: string[];
  timestamp: number;
}

export interface QualityIssue {
  type: 'missing_info' | 'unclear' | 'incorrect' | 'incomplete' | 'off_topic' | 'too_verbose' | 'too_brief';
  description: string;
  severity: 'low' | 'medium' | 'high';
  location?: string;
  suggestion?: string;
}

export interface SelfReflection {
  id: string;
  question: string;
  answer: string;
  confidence: number;
  reasoning: string;
  timestamp: number;
}

export interface ImprovementResult {
  originalResponse: string;
  improvedResponse: string;
  changes: string[];
  qualityImprovement: number;
}

// Seuils de qualit√©
const QUALITY_THRESHOLDS = {
  EXCELLENT: 0.9,
  GOOD: 0.75,
  ACCEPTABLE: 0.6,
  NEEDS_IMPROVEMENT: 0.4,
  POOR: 0.2
};

/**
 * Classe principale de m√©ta-cognition
 */
export class MetaCognition {
  private assessmentHistory: QualityAssessment[] = [];
  private reflectionHistory: SelfReflection[] = [];

  constructor() {
    this.assessmentHistory = [];
    this.reflectionHistory = [];
  }

  /**
   * √âvalue la qualit√© d'une r√©ponse
   */
  async assessQuality(
    response: string,
    originalRequest: string,
    context?: string[]
  ): Promise<QualityAssessment> {
    console.log('[MetaCognition] Assessing response quality');

    const prompt = `√âvalue la qualit√© de cette r√©ponse:

Demande originale: "${originalRequest}"
R√©ponse: "${response.substring(0, 2000)}"
${context ? `Contexte: ${context.slice(-3).join(' | ')}` : ''}

√âvalue sur une √©chelle de 0 √† 1:
1. Pertinence: La r√©ponse r√©pond-elle √† la demande?
2. Compl√©tude: La r√©ponse couvre-t-elle tous les aspects?
3. Exactitude: Les informations sont-elles correctes?
4. Clart√©: La r√©ponse est-elle claire et bien structur√©e?
5. Utilit√©: La r√©ponse aide-t-elle vraiment l'utilisateur?

Identifie aussi les probl√®mes et suggestions d'am√©lioration.

R√©ponds en JSON:
{
  "scores": {
    "relevance": 0.0-1.0,
    "completeness": 0.0-1.0,
    "accuracy": 0.0-1.0,
    "clarity": 0.0-1.0,
    "helpfulness": 0.0-1.0
  },
  "issues": [
    {
      "type": "missing_info|unclear|incorrect|incomplete|off_topic|too_verbose|too_brief",
      "description": "...",
      "severity": "low|medium|high",
      "suggestion": "..."
    }
  ],
  "suggestions": ["..."]
}`;

    try {
      const response_llm = await invokeLLM({
        messages: [
          { role: 'system', content: 'Tu √©values la qualit√© des r√©ponses de mani√®re objective et constructive.' },
          { role: 'user', content: prompt }
        ],
        response_format: { type: 'json_object' }
      });

      const content = response_llm.choices[0]?.message?.content;
      if (typeof content === 'string') {
        const result = JSON.parse(content);

        const scores = result.scores || {
          relevance: 0.7,
          completeness: 0.7,
          accuracy: 0.7,
          clarity: 0.7,
          helpfulness: 0.7
        };

        const overallScore = (
          scores.relevance * 0.25 +
          scores.completeness * 0.2 +
          scores.accuracy * 0.25 +
          scores.clarity * 0.15 +
          scores.helpfulness * 0.15
        );

        const assessment: QualityAssessment = {
          id: `assess_${Date.now()}`,
          responseId: `resp_${Date.now()}`,
          scores,
          overallScore,
          issues: result.issues || [],
          suggestions: result.suggestions || [],
          timestamp: Date.now()
        };

        this.assessmentHistory.push(assessment);
        return assessment;
      }
    } catch (error) {
      console.error('[MetaCognition] Error assessing quality:', error);
    }

    // √âvaluation par d√©faut
    return {
      id: `assess_${Date.now()}`,
      responseId: `resp_${Date.now()}`,
      scores: {
        relevance: 0.7,
        completeness: 0.7,
        accuracy: 0.7,
        clarity: 0.7,
        helpfulness: 0.7
      },
      overallScore: 0.7,
      issues: [],
      suggestions: [],
      timestamp: Date.now()
    };
  }

  /**
   * Am√©liore une r√©ponse bas√©e sur l'√©valuation
   */
  async improveResponse(
    response: string,
    assessment: QualityAssessment,
    originalRequest: string
  ): Promise<ImprovementResult> {
    console.log('[MetaCognition] Improving response based on assessment');

    // Si la qualit√© est d√©j√† excellente, pas besoin d'am√©liorer
    if (assessment.overallScore >= QUALITY_THRESHOLDS.EXCELLENT) {
      return {
        originalResponse: response,
        improvedResponse: response,
        changes: [],
        qualityImprovement: 0
      };
    }

    const issuesText = assessment.issues
      .map(i => `- ${i.type}: ${i.description} (${i.severity})`)
      .join('\n');

    const prompt = `Am√©liore cette r√©ponse en corrigeant les probl√®mes identifi√©s:

Demande originale: "${originalRequest}"
R√©ponse actuelle: "${response}"

Probl√®mes identifi√©s:
${issuesText}

Suggestions:
${assessment.suggestions.join('\n')}

Score actuel: ${(assessment.overallScore * 100).toFixed(0)}%

G√©n√®re une version am√©lior√©e qui:
1. Corrige tous les probl√®mes identifi√©s
2. Applique les suggestions
3. Maintient le ton et le style appropri√©s

R√©ponds en JSON:
{
  "improvedResponse": "...",
  "changes": ["changement 1", "changement 2"],
  "expectedImprovement": 0.0-1.0
}`;

    try {
      const response_llm = await invokeLLM({
        messages: [
          { role: 'system', content: 'Tu am√©liores les r√©ponses de mani√®re constructive.' },
          { role: 'user', content: prompt }
        ],
        response_format: { type: 'json_object' }
      });

      const content = response_llm.choices[0]?.message?.content;
      if (typeof content === 'string') {
        const result = JSON.parse(content);

        return {
          originalResponse: response,
          improvedResponse: result.improvedResponse || response,
          changes: result.changes || [],
          qualityImprovement: result.expectedImprovement || 0.1
        };
      }
    } catch (error) {
      console.error('[MetaCognition] Error improving response:', error);
    }

    return {
      originalResponse: response,
      improvedResponse: response,
      changes: [],
      qualityImprovement: 0
    };
  }

  /**
   * Effectue une auto-r√©flexion sur une question
   */
  async selfReflect(question: string): Promise<SelfReflection> {
    console.log('[MetaCognition] Self-reflecting on:', question);

    const prompt = `R√©fl√©chis √† cette question sur ta propre performance:

Question: "${question}"

Analyse honn√™tement:
1. Ta r√©ponse √† cette question
2. Ta confiance dans cette r√©ponse
3. Le raisonnement derri√®re ta r√©ponse

R√©ponds en JSON:
{
  "answer": "...",
  "confidence": 0.0-1.0,
  "reasoning": "..."
}`;

    try {
      const response = await invokeLLM({
        messages: [
          { role: 'system', content: 'Tu pratiques l\'auto-r√©flexion honn√™te et constructive.' },
          { role: 'user', content: prompt }
        ],
        response_format: { type: 'json_object' }
      });

      const content = response.choices[0]?.message?.content;
      if (typeof content === 'string') {
        const result = JSON.parse(content);

        const reflection: SelfReflection = {
          id: `reflect_${Date.now()}`,
          question,
          answer: result.answer || 'R√©flexion non disponible',
          confidence: result.confidence || 0.5,
          reasoning: result.reasoning || '',
          timestamp: Date.now()
        };

        this.reflectionHistory.push(reflection);
        return reflection;
      }
    } catch (error) {
      console.error('[MetaCognition] Error in self-reflection:', error);
    }

    return {
      id: `reflect_${Date.now()}`,
      question,
      answer: 'R√©flexion non disponible',
      confidence: 0.5,
      reasoning: '',
      timestamp: Date.now()
    };
  }

  /**
   * V√©rifie si une r√©ponse est pr√™te √† √™tre livr√©e
   */
  async isReadyToDeliver(
    response: string,
    originalRequest: string
  ): Promise<{ ready: boolean; reason: string; assessment: QualityAssessment }> {
    const assessment = await this.assessQuality(response, originalRequest);

    if (assessment.overallScore >= QUALITY_THRESHOLDS.GOOD) {
      return {
        ready: true,
        reason: 'Qualit√© suffisante pour livraison',
        assessment
      };
    }

    if (assessment.overallScore >= QUALITY_THRESHOLDS.ACCEPTABLE) {
      // V√©rifier s'il y a des probl√®mes critiques
      const criticalIssues = assessment.issues.filter(i => i.severity === 'high');
      if (criticalIssues.length === 0) {
        return {
          ready: true,
          reason: 'Qualit√© acceptable, pas de probl√®mes critiques',
          assessment
        };
      }
    }

    return {
      ready: false,
      reason: `Qualit√© insuffisante (${(assessment.overallScore * 100).toFixed(0)}%). Probl√®mes: ${assessment.issues.map(i => i.description).join(', ')}`,
      assessment
    };
  }

  /**
   * G√©n√®re un rapport de qualit√©
   */
  generateQualityReport(): string {
    if (this.assessmentHistory.length === 0) {
      return 'Aucune √©valuation disponible.';
    }

    const avgScore = this.assessmentHistory.reduce((sum, a) => sum + a.overallScore, 0) / this.assessmentHistory.length;
    const recentAssessments = this.assessmentHistory.slice(-5);

    const report = `üìä **Rapport de Qualit√©**

**Score moyen:** ${(avgScore * 100).toFixed(1)}%

**Derni√®res √©valuations:**
${recentAssessments.map(a => `- ${(a.overallScore * 100).toFixed(0)}% (${a.issues.length} probl√®mes)`).join('\n')}

**Probl√®mes fr√©quents:**
${this.getMostCommonIssues().join('\n')}
`;

    return report;
  }

  /**
   * Obtient les probl√®mes les plus fr√©quents
   */
  private getMostCommonIssues(): string[] {
    const issueCounts = new Map<string, number>();

    this.assessmentHistory.forEach(assessment => {
      assessment.issues.forEach(issue => {
        const count = issueCounts.get(issue.type) || 0;
        issueCounts.set(issue.type, count + 1);
      });
    });

    return Array.from(issueCounts.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(0, 5)
      .map(([type, count]) => `- ${type}: ${count} occurrences`);
  }

  /**
   * Questions de r√©flexion standards
   */
  async performStandardReflection(): Promise<SelfReflection[]> {
    const questions = [
      'Ma r√©ponse r√©pond-elle vraiment √† ce que l\'utilisateur demande?',
      'Y a-t-il des informations importantes que j\'ai omises?',
      'Ma r√©ponse est-elle claire et facile √† comprendre?',
      'Ai-je fait des suppositions non v√©rifi√©es?',
      'Comment puis-je am√©liorer ma prochaine r√©ponse?'
    ];

    const reflections: SelfReflection[] = [];

    for (const question of questions) {
      const reflection = await this.selfReflect(question);
      reflections.push(reflection);
    }

    return reflections;
  }

  /**
   * Obtient l'historique des √©valuations
   */
  getAssessmentHistory(): QualityAssessment[] {
    return [...this.assessmentHistory];
  }

  /**
   * Obtient l'historique des r√©flexions
   */
  getReflectionHistory(): SelfReflection[] {
    return [...this.reflectionHistory];
  }

  /**
   * R√©initialise le module
   */
  reset(): void {
    this.assessmentHistory = [];
    this.reflectionHistory = [];
  }
}

// Instance singleton
let metaCognitionInstance: MetaCognition | null = null;

export function getMetaCognition(): MetaCognition {
  if (!metaCognitionInstance) {
    metaCognitionInstance = new MetaCognition();
  }
  return metaCognitionInstance;
}

export default MetaCognition;

/**
 * ManusLikeCognition - Capacit√©s cognitives avanc√©es inspir√©es de Manus AI
 * 
 * Ce module unifie les 4 capacit√©s cognitives cl√©s :
 * 1. Gestion d'ambigu√Øt√© - D√©tection et r√©solution des demandes floues
 * 2. M√©tacognition - Auto-√©valuation et r√©flexion sur le raisonnement
 * 3. M√©moire de travail - Contexte persistant entre les √©changes
 * 4. Initiative proactive - Suggestions et anticipation des besoins
 */

import { invokeLLM } from '../_core/llm';
import { getHypothesisEngine } from './hypothesisEngine';
import { getMetaCognition } from './metaCognition';
import { getWorkingMemory } from './workingMemory';
import { getProactiveEngine } from './proactiveEngine';

// Types pour la gestion d'ambigu√Øt√©
export interface AmbiguityResolution {
  isAmbiguous: boolean;
  ambiguityLevel: 'none' | 'low' | 'medium' | 'high';
  clarificationNeeded: boolean;
  clarificationQuestions: ClarificationQuestion[];
  bestInterpretation: string;
  alternativeInterpretations: string[];
  confidence: number;
  reasoning: string;
}

export interface ClarificationQuestion {
  id: string;
  question: string;
  options?: string[];
  type: 'choice' | 'open' | 'confirmation';
  priority: 'required' | 'optional';
  context: string;
}

// Types pour la m√©tacognition
export interface MetacognitiveState {
  currentConfidence: number;
  uncertaintyAreas: string[];
  knowledgeLimits: string[];
  reasoningQuality: 'poor' | 'fair' | 'good' | 'excellent';
  selfCorrections: string[];
  reflections: string[];
}

// Types pour la m√©moire de travail
export interface WorkingMemoryState {
  currentTopic: string;
  recentEntities: string[];
  userPreferences: Record<string, any>;
  pendingTasks: string[];
  conversationSummary: string;
  importantFacts: string[];
}

// Types pour l'initiative proactive
export interface ProactiveState {
  suggestions: ProactiveSuggestion[];
  anticipatedNeeds: string[];
  alerts: string[];
  opportunities: string[];
}

export interface ProactiveSuggestion {
  id: string;
  type: 'action' | 'information' | 'clarification' | 'optimization';
  content: string;
  relevance: number;
  context: string;
}

// Analyse cognitive compl√®te
export interface CognitiveAnalysis {
  ambiguity: AmbiguityResolution;
  metacognition: MetacognitiveState;
  memory: WorkingMemoryState;
  proactive: ProactiveState;
  overallReadiness: number;
  recommendedAction: 'proceed' | 'clarify' | 'defer' | 'suggest_alternative';
}

// R√©ponse cognitive pr√©par√©e
export interface CognitiveResponse {
  shouldProceed: boolean;
  clarificationNeeded: boolean;
  clarificationMessage?: string;
  confidenceLevel: number;
  metacognitiveNotes: string[];
  proactiveSuggestions: string[];
  memoryContext: string;
}

/**
 * ManusLikeCognition - Classe principale pour les capacit√©s cognitives
 */
export class ManusLikeCognition {
  private hypothesisEngine = getHypothesisEngine();
  private metaCognition = getMetaCognition();
  private workingMemory = getWorkingMemory();
  private proactiveEngine = getProactiveEngine();

  /**
   * Analyse l'ambigu√Øt√© d'un message utilisateur
   */
  async analyzeAmbiguity(
    message: string,
    conversationHistory: Array<{ role: string; content: string }>,
    detectedIntent: string
  ): Promise<AmbiguityResolution> {
    try {
      const response = await invokeLLM({
        messages: [
          {
            role: 'system',
            content: `Tu es un analyseur d'ambigu√Øt√© expert. Analyse le message utilisateur et d√©termine :
1. Si le message est ambigu ou incomplet
2. Le niveau d'ambigu√Øt√© (none, low, medium, high)
3. Si une clarification est n√©cessaire
4. Les questions de clarification √† poser
5. La meilleure interpr√©tation possible
6. Les interpr√©tations alternatives

Contexte de l'intention d√©tect√©e: ${detectedIntent}

R√©ponds en JSON avec ce format:
{
  "isAmbiguous": boolean,
  "ambiguityLevel": "none" | "low" | "medium" | "high",
  "clarificationNeeded": boolean,
  "clarificationQuestions": [{"id": string, "question": string, "options": string[], "type": "choice" | "open" | "confirmation", "priority": "required" | "optional", "context": string}],
  "bestInterpretation": string,
  "alternativeInterpretations": string[],
  "confidence": number (0-1),
  "reasoning": string
}`
          },
          ...conversationHistory.slice(-5).map(m => ({
            role: m.role as 'user' | 'assistant',
            content: m.content
          })),
          { role: 'user', content: message }
        ],
        response_format: {
          type: 'json_schema',
          json_schema: {
            name: 'ambiguity_analysis',
            strict: true,
            schema: {
              type: 'object',
              properties: {
                isAmbiguous: { type: 'boolean' },
                ambiguityLevel: { type: 'string', enum: ['none', 'low', 'medium', 'high'] },
                clarificationNeeded: { type: 'boolean' },
                clarificationQuestions: {
                  type: 'array',
                  items: {
                    type: 'object',
                    properties: {
                      id: { type: 'string' },
                      question: { type: 'string' },
                      options: { type: 'array', items: { type: 'string' } },
                      type: { type: 'string', enum: ['choice', 'open', 'confirmation'] },
                      priority: { type: 'string', enum: ['required', 'optional'] },
                      context: { type: 'string' }
                    },
                    required: ['id', 'question', 'type', 'priority', 'context'],
                    additionalProperties: false
                  }
                },
                bestInterpretation: { type: 'string' },
                alternativeInterpretations: { type: 'array', items: { type: 'string' } },
                confidence: { type: 'number' },
                reasoning: { type: 'string' }
              },
              required: ['isAmbiguous', 'ambiguityLevel', 'clarificationNeeded', 'clarificationQuestions', 'bestInterpretation', 'alternativeInterpretations', 'confidence', 'reasoning'],
              additionalProperties: false
            }
          }
        }
      });

      const content = response.choices[0]?.message?.content;
      if (content && typeof content === 'string') {
        return JSON.parse(content);
      }
    } catch (error) {
      console.error('[ManusLikeCognition] Erreur analyse ambigu√Øt√©:', error);
    }

    // Retour par d√©faut si erreur
    return {
      isAmbiguous: false,
      ambiguityLevel: 'none',
      clarificationNeeded: false,
      clarificationQuestions: [],
      bestInterpretation: message,
      alternativeInterpretations: [],
      confidence: 0.7,
      reasoning: 'Analyse par d√©faut'
    };
  }

  /**
   * √âvalue l'√©tat m√©tacognitif pour une requ√™te
   */
  async evaluateMetacognition(
    message: string,
    detectedIntent: string
  ): Promise<MetacognitiveState> {
    try {
      const response = await invokeLLM({
        messages: [
          {
            role: 'system',
            content: `Tu es un syst√®me de m√©tacognition. √âvalue ta propre capacit√© √† r√©pondre √† cette requ√™te.
Analyse :
1. Ton niveau de confiance pour cette t√¢che
2. Les zones d'incertitude
3. Les limites de tes connaissances
4. La qualit√© de ton raisonnement
5. Les corrections potentielles √† apporter
6. Tes r√©flexions sur la t√¢che

Type de requ√™te: ${detectedIntent}

R√©ponds en JSON:
{
  "currentConfidence": number (0-1),
  "uncertaintyAreas": string[],
  "knowledgeLimits": string[],
  "reasoningQuality": "poor" | "fair" | "good" | "excellent",
  "selfCorrections": string[],
  "reflections": string[]
}`
          },
          { role: 'user', content: message }
        ],
        response_format: {
          type: 'json_schema',
          json_schema: {
            name: 'metacognition_evaluation',
            strict: true,
            schema: {
              type: 'object',
              properties: {
                currentConfidence: { type: 'number' },
                uncertaintyAreas: { type: 'array', items: { type: 'string' } },
                knowledgeLimits: { type: 'array', items: { type: 'string' } },
                reasoningQuality: { type: 'string', enum: ['poor', 'fair', 'good', 'excellent'] },
                selfCorrections: { type: 'array', items: { type: 'string' } },
                reflections: { type: 'array', items: { type: 'string' } }
              },
              required: ['currentConfidence', 'uncertaintyAreas', 'knowledgeLimits', 'reasoningQuality', 'selfCorrections', 'reflections'],
              additionalProperties: false
            }
          }
        }
      });

      const content = response.choices[0]?.message?.content;
      if (content && typeof content === 'string') {
        return JSON.parse(content);
      }
    } catch (error) {
      console.error('[ManusLikeCognition] Erreur √©valuation m√©tacognition:', error);
    }

    return {
      currentConfidence: 0.7,
      uncertaintyAreas: [],
      knowledgeLimits: [],
      reasoningQuality: 'good',
      selfCorrections: [],
      reflections: []
    };
  }

  /**
   * Met √† jour la m√©moire de travail
   */
  updateWorkingMemory(
    message: string,
    intent: string,
    entities: string[] = []
  ): WorkingMemoryState {
    // Stocker le message dans la m√©moire
    this.workingMemory.store(`message_${Date.now()}`, {
      content: message,
      intent,
      entities,
      timestamp: Date.now()
    });

    // Mettre √† jour le contexte
    const context = this.workingMemory.getContext();
    
    return {
      currentTopic: context.currentTopic || intent,
      recentEntities: entities,
      userPreferences: Object.fromEntries(context.userPreferences || new Map()),
      pendingTasks: context.recentActions || [],
      conversationSummary: '',
      importantFacts: []
    };
  }

  /**
   * R√©cup√®re l'√©tat actuel de la m√©moire de travail
   */
  getWorkingMemoryState(): WorkingMemoryState {
    const context = this.workingMemory.getContext();
    
    return {
      currentTopic: context.currentTopic || '',
      recentEntities: Array.from(context.entities?.keys() || []),
      userPreferences: Object.fromEntries(context.userPreferences || new Map()),
      pendingTasks: context.recentActions || [],
      conversationSummary: '',
      importantFacts: []
    };
  }

  /**
   * G√©n√®re des suggestions proactives
   */
  async generateProactiveSuggestions(
    message: string,
    intent: string
  ): Promise<ProactiveSuggestion[]> {
    try {
      const suggestions = await this.proactiveEngine.generateSuggestions(
        'cognitive_analysis',
        intent as any,
        message,
        []
      );
      
      return suggestions.map((s: any, i: number) => ({
        id: `suggestion_${i}`,
        type: s.type || 'action',
        content: s.description || s.title || s.content || '',
        relevance: s.confidence || 0.7,
        context: intent
      }));
    } catch (error) {
      console.error('[ManusLikeCognition] Erreur g√©n√©ration suggestions:', error);
      return [];
    }
  }

  /**
   * Anticipe les besoins de l'utilisateur
   */
  async anticipateNeeds(
    message: string,
    intent: string
  ): Promise<string[]> {
    try {
      const response = await invokeLLM({
        messages: [
          {
            role: 'system',
            content: `Tu es un syst√®me d'anticipation des besoins utilisateur.
Bas√© sur le message et l'intention d√©tect√©e, anticipe ce que l'utilisateur pourrait vouloir ensuite.

Intention: ${intent}

R√©ponds en JSON:
{
  "anticipatedNeeds": string[]
}`
          },
          { role: 'user', content: message }
        ],
        response_format: {
          type: 'json_schema',
          json_schema: {
            name: 'needs_anticipation',
            strict: true,
            schema: {
              type: 'object',
              properties: {
                anticipatedNeeds: { type: 'array', items: { type: 'string' } }
              },
              required: ['anticipatedNeeds'],
              additionalProperties: false
            }
          }
        }
      });

      const content = response.choices[0]?.message?.content;
      if (content && typeof content === 'string') {
        const parsed = JSON.parse(content);
        return parsed.anticipatedNeeds || [];
      }
    } catch (error) {
      console.error('[ManusLikeCognition] Erreur anticipation besoins:', error);
    }

    return [];
  }

  /**
   * Effectue une analyse cognitive compl√®te
   */
  async analyzeCompletely(
    message: string,
    conversationHistory: Array<{ role: string; content: string }>,
    detectedIntent: string
  ): Promise<CognitiveAnalysis> {
    // Ex√©cuter les analyses en parall√®le pour la performance
    const [ambiguity, metacognition, anticipatedNeeds] = await Promise.all([
      this.analyzeAmbiguity(message, conversationHistory, detectedIntent),
      this.evaluateMetacognition(message, detectedIntent),
      this.anticipateNeeds(message, detectedIntent)
    ]);

    // Mettre √† jour la m√©moire de travail
    const memory = this.updateWorkingMemory(message, detectedIntent);

    // G√©n√©rer les suggestions proactives
    const suggestions = await this.generateProactiveSuggestions(message, detectedIntent);

    // Construire l'√©tat proactif
    const proactive: ProactiveState = {
      suggestions,
      anticipatedNeeds,
      alerts: [],
      opportunities: []
    };

    // Calculer la pr√©paration globale
    const overallReadiness = this.calculateReadiness(ambiguity, metacognition);

    // D√©terminer l'action recommand√©e
    const recommendedAction = this.determineAction(ambiguity, metacognition, overallReadiness);

    return {
      ambiguity,
      metacognition,
      memory,
      proactive,
      overallReadiness,
      recommendedAction
    };
  }

  /**
   * Calcule le niveau de pr√©paration global
   */
  private calculateReadiness(
    ambiguity: AmbiguityResolution,
    metacognition: MetacognitiveState
  ): number {
    const ambiguityScore = ambiguity.isAmbiguous ? 
      (ambiguity.ambiguityLevel === 'high' ? 0.3 : 
       ambiguity.ambiguityLevel === 'medium' ? 0.5 : 
       ambiguity.ambiguityLevel === 'low' ? 0.7 : 1) : 1;
    
    const confidenceScore = metacognition.currentConfidence;
    
    const qualityScore = 
      metacognition.reasoningQuality === 'excellent' ? 1 :
      metacognition.reasoningQuality === 'good' ? 0.8 :
      metacognition.reasoningQuality === 'fair' ? 0.6 : 0.4;

    return (ambiguityScore * 0.4 + confidenceScore * 0.4 + qualityScore * 0.2);
  }

  /**
   * D√©termine l'action recommand√©e
   */
  private determineAction(
    ambiguity: AmbiguityResolution,
    metacognition: MetacognitiveState,
    readiness: number
  ): 'proceed' | 'clarify' | 'defer' | 'suggest_alternative' {
    if (ambiguity.clarificationNeeded && ambiguity.ambiguityLevel === 'high') {
      return 'clarify';
    }
    
    if (readiness < 0.4) {
      return 'defer';
    }
    
    if (metacognition.currentConfidence < 0.5 && ambiguity.alternativeInterpretations.length > 0) {
      return 'suggest_alternative';
    }
    
    return 'proceed';
  }

  /**
   * G√©n√®re un message de clarification si n√©cessaire
   */
  generateClarificationMessage(resolution: AmbiguityResolution): string {
    if (!resolution.clarificationNeeded || resolution.clarificationQuestions.length === 0) {
      return '';
    }

    const requiredQuestions = resolution.clarificationQuestions
      .filter(q => q.priority === 'required');

    if (requiredQuestions.length === 0) {
      return '';
    }

    let message = "J'ai besoin d'une petite pr√©cision pour mieux vous aider :\n\n";
    
    requiredQuestions.forEach((q, i) => {
      message += `${i + 1}. ${q.question}`;
      if (q.options && q.options.length > 0) {
        message += `\n   Options: ${q.options.join(', ')}`;
      }
      message += '\n';
    });

    return message;
  }

  /**
   * G√©n√®re des notes m√©tacognitives pour la r√©ponse
   */
  private generateMetacognitiveNotes(state: MetacognitiveState): string[] {
    const notes: string[] = [];

    if (state.currentConfidence < 0.5) {
      notes.push('‚ö†Ô∏è Confiance limit√©e - Je vous recommande de v√©rifier ces informations');
    }

    if (state.uncertaintyAreas.length > 0) {
      notes.push(`üìä Zones d'incertitude: ${state.uncertaintyAreas.join(', ')}`);
    }

    if (state.knowledgeLimits.length > 0) {
      notes.push(`üìö Limites: ${state.knowledgeLimits.join(', ')}`);
    }

    if (state.selfCorrections.length > 0) {
      notes.push(`üîÑ Corrections: ${state.selfCorrections.join(', ')}`);
    }

    return notes;
  }

  /**
   * Pr√©pare une r√©ponse cognitive compl√®te
   */
  prepareCognitiveResponse(analysis: CognitiveAnalysis): CognitiveResponse {
    const clarificationMessage = this.generateClarificationMessage(analysis.ambiguity);
    const metacognitiveNotes = this.generateMetacognitiveNotes(analysis.metacognition);
    
    const proactiveSuggestions = analysis.proactive.suggestions
      .filter(s => s.relevance > 0.5)
      .map(s => s.content);

    // Construire le contexte m√©moire
    let memoryContext = '';
    if (analysis.memory.currentTopic) {
      memoryContext += `Sujet actuel: ${analysis.memory.currentTopic}. `;
    }
    if (analysis.memory.recentEntities.length > 0) {
      memoryContext += `Entit√©s mentionn√©es: ${analysis.memory.recentEntities.join(', ')}. `;
    }

    return {
      shouldProceed: analysis.recommendedAction === 'proceed',
      clarificationNeeded: analysis.recommendedAction === 'clarify',
      clarificationMessage: clarificationMessage || undefined,
      confidenceLevel: analysis.metacognition.currentConfidence,
      metacognitiveNotes,
      proactiveSuggestions,
      memoryContext
    };
  }

  /**
   * R√©initialise l'√©tat cognitif
   */
  reset(): void {
    this.hypothesisEngine.reset();
    this.metaCognition.reset();
    this.workingMemory.reset();
    this.proactiveEngine.reset();
    console.log('[ManusLikeCognition] √âtat cognitif r√©initialis√©');
  }

  /**
   * Retourne le statut du syst√®me cognitif
   */
  getStatus(): string {
    const memory = this.getWorkingMemoryState();
    return `
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    √âtat Cognitif Phoenix
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìù Sujet actuel: ${memory.currentTopic || 'Aucun'}
üè∑Ô∏è  Entit√©s r√©centes: ${memory.recentEntities.length > 0 ? memory.recentEntities.join(', ') : 'Aucune'}
üìã T√¢ches en attente: ${memory.pendingTasks.length}
‚öôÔ∏è  Pr√©f√©rences: ${Object.keys(memory.userPreferences).length} enregistr√©es
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê`;
  }
}

// Singleton
let instance: ManusLikeCognition | null = null;

export function getManusLikeCognition(): ManusLikeCognition {
  if (!instance) {
    instance = new ManusLikeCognition();
  }
  return instance;
}

export default ManusLikeCognition;
